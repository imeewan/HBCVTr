{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Pk7uqVkjGkM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anaconda Setup"
      ],
      "metadata": {
        "id": "sPfWLSXxGmoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we set up Anaconda environment to install all necessary packages."
      ],
      "metadata": {
        "id": "f7-iOwixGoDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbzBkP1E6wng",
        "outputId": "be93e8f5-02c7-4424-af4d-13022dcbe8bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:13\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that Anaconda is installed properly and also check the version of Anaconda."
      ],
      "metadata": {
        "id": "dKF9dyt3Gv9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8dYGFEZ7tvW",
        "outputId": "ea17cbc7-50af-4979-a860-a5bdc7729f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 23.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNeWJKm770K1",
        "outputId": "b701b38a-2672-4381-d5ec-a7686ca0bc07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can install all necessary packages to run HBCVTr via Anaconda and pip."
      ],
      "metadata": {
        "id": "QL8rcO4WG8Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge rdkit=2023.3.2 -y\n",
        "!conda install -c conda-forge deepsmiles\n",
        "!pip install transformers==4.31.0 SmilesPE==0.0.3"
      ],
      "metadata": {
        "id": "eiWp-2mW8FFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Git Repository"
      ],
      "metadata": {
        "id": "3IdFCwajG1dT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the repository from Github"
      ],
      "metadata": {
        "id": "TdYlBa_kHEP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MD7NeA_4_wv",
        "outputId": "4a63344b-929f-4b18-ec78-c7dbd884d43a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HBCVTr'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 131 (delta 36), reused 0 (delta 0), pack-reused 70\u001b[K\n",
            "Receiving objects: 100% (131/131), 170.07 KiB | 2.43 MiB/s, done.\n",
            "Resolving deltas: 100% (70/70), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/imeewan/HBCVTr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change directory to the cloned repository."
      ],
      "metadata": {
        "id": "7lVLobK2HGcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd HBCVTr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztuFTNXT9vkG",
        "outputId": "e693f241-d24d-4181-9393-9fbd16a566d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HBCVTr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Models"
      ],
      "metadata": {
        "id": "nxoIHlDCJ-xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we download the trained models from Google Drive."
      ],
      "metadata": {
        "id": "cxp4Ay94KASG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1hDDNY9kE3Y-IFJEeILDxwG5NbRWMCWA8\n",
        "!gdown --id 1vAkxP3y-FD5N5BpbfXIzTn5-nORlnv4T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsoUJ9OlIZL2",
        "outputId": "0d611b8a-9413-4810-8992-70bce76ba3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hDDNY9kE3Y-IFJEeILDxwG5NbRWMCWA8\n",
            "To: /content/HBCVTr/hbv_model.pt\n",
            "100% 1.12G/1.12G [00:15<00:00, 71.9MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vAkxP3y-FD5N5BpbfXIzTn5-nORlnv4T\n",
            "To: /content/HBCVTr/hcv_model.pt\n",
            "100% 1.12G/1.12G [00:13<00:00, 80.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv hbv_model.pt model/\n",
        "!mv hcv_model.pt model/"
      ],
      "metadata": {
        "id": "lix2ntzMTs98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Demo"
      ],
      "metadata": {
        "id": "6AOCzenpHK6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo, we will run a prediction using our HBCVTr model."
      ],
      "metadata": {
        "id": "il3nDeMCHOT-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's import all necessary packages."
      ],
      "metadata": {
        "id": "TqBbehy4HYj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from BartDataset import BartDataset\n",
        "from CustomBart_Atomic_Tokenizer import CustomBart_Atomic_Tokenizer\n",
        "from CustomBart_FG_Tokenizer import CustomBart_FG_Tokenizer\n",
        "from TqdmWrap import TqdmWrap\n",
        "from DualInputDataset import DualInputDataset\n",
        "from DualBartModel import DualBartModel, CustomBartModel\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, Dataset\n",
        "from torch.optim import AdamW\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import deepsmiles\n",
        "from SmilesPE.tokenizer import *\n",
        "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from rdkit import Chem\n",
        "import codecs\n",
        "from transformers import AdamW, BartTokenizer, BartForConditionalGeneration, BartConfig, get_linear_schedule_with_warmup, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, PreTrainedTokenizer\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import json\n",
        "import os\n",
        "from utils import *\n",
        "from pretrained_utils import *\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import SaltRemover"
      ],
      "metadata": {
        "id": "gsmwv3zo5XMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input the smiles and virus choice to predict here."
      ],
      "metadata": {
        "id": "g9-Vktljmacj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# smiles = input(\"Enter the SMILES of the compound: \")\n",
        "smiles = 'C[C@H](Cn1cnc2c(N)ncnc21)OCP(=O)(O)OP(=O)(O)CO[C@H](C)Cn1cnc2c(N)ncnc21'\n",
        "# virus_choice = input(\"Do you want to predict the compound's activity against HBV or HCV? (Enter HBV or HCV): \").lower()\n",
        "virus_choice = 'hbv'"
      ],
      "metadata": {
        "id": "qHH4gjRHmYmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we run the prediction."
      ],
      "metadata": {
        "id": "w-FO2giEmeQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Analysis in progress ...\")\n",
        "\n",
        "if virus_choice == 'hbv':\n",
        "  model_path = \"model/hbv_model.pt\"\n",
        "  max_pact = max_pact_hbv\n",
        "  min_pact = min_pact_hbv\n",
        "elif virus_choice == 'hcv':\n",
        "  model_path = \"model/hcv_model.pt\"\n",
        "  max_pact = max_pact_hcv\n",
        "  min_pact = min_pact_hcv\n",
        "else:\n",
        "  raise ValueError(\"Invalid input. Please enter either 'HBV' or 'HCV'.\")\n",
        "\n",
        "max_length = 250\n",
        "\n",
        "model = DualBartModel(config1, config2, reg_mod)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "smiles_data_no_salt = remove_salt(smiles)\n",
        "smiles = smiles_data_no_salt\n",
        "\n",
        "input_encoding1 = tokenizer1.encode_plus(smiles, truncation=True, max_length=max_length, padding='max_length', return_tensors=\"pt\")\n",
        "input_encoding2 = tokenizer2.encode_plus(smiles, truncation=True, max_length=max_length, padding='max_length', return_tensors=\"pt\")\n",
        "\n",
        "input_ids1 = input_encoding1['input_ids'].to(device)\n",
        "attention_mask1 = input_encoding1['attention_mask'].to(device)\n",
        "input_ids2 = input_encoding2['input_ids'].to(device)\n",
        "attention_mask2 = input_encoding2['attention_mask'].to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(input_ids1=input_ids1, attention_mask1=attention_mask1,\n",
        "                  input_ids2=input_ids2, attention_mask2=attention_mask2)\n",
        "\n",
        "prediction = output\n",
        "prediction_value = prediction.cpu().numpy()[0]\n",
        "print('SMILES: ', smiles)\n",
        "print('Predicted pACT: ', prediction_value * (max_pact - min_pact) + min_pact)\n",
        "predicted_EC50 = 10**-(prediction_value * (max_pact - min_pact) + min_pact) * 10**9\n",
        "print('Predicted EC50 :', predicted_EC50, 'nM')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POoCv3Fz5j5a",
        "outputId": "1cf3c731-21c5-48c4-e766-369a132a922d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis in progress ...\n",
            "SMILES:  C[C@H](Cn1cnc2c(N)ncnc21)OCP(=O)(O)OP(=O)(O)CO[C@H](C)Cn1cnc2c(N)ncnc21\n",
            "Predicted pACT:  8.122957168817521\n",
            "Predicted EC50 : 7.534298651631602 nM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zndUo6DTXW8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}