{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Pk7uqVkjGkM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anaconda Setup"
      ],
      "metadata": {
        "id": "sPfWLSXxGmoT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we set up Anaconda environment to install all necessary packages.\n",
        "Note that after running this block, the Colab Kernel will restart. After restarting the Kernel, proceed to the next block."
      ],
      "metadata": {
        "id": "f7-iOwixGoDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbzBkP1E6wng",
        "outputId": "8b409e5e-36f3-432f-8f46-06d0a4127ce9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:15\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check that Anaconda is installed properly and also check the version of Anaconda."
      ],
      "metadata": {
        "id": "dKF9dyt3Gv9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8dYGFEZ7tvW",
        "outputId": "66454210-59c5-45a5-bc2e-8cf654b1b02a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 23.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNeWJKm770K1",
        "outputId": "74ef9a95-1038-40d1-9eae-3a18a017aa1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ¨ðŸ°âœ¨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can install all necessary packages to run HBCVTr via Anaconda and pip."
      ],
      "metadata": {
        "id": "QL8rcO4WG8Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge rdkit=2023.3.2 -y\n",
        "!conda install -c conda-forge deepsmiles\n",
        "!pip install transformers==4.31.0 SmilesPE==0.0.3"
      ],
      "metadata": {
        "id": "eiWp-2mW8FFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdefe130-0220-49e7-d05a-8c2a0e3d8177"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bfailed with repodata from current_repodata.json, will retry with next repodata source.\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit=2023.3.2\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boltons-23.0.0             |     pyhd8ed1ab_0         296 KB  conda-forge\n",
            "    boost-1.78.0               |  py310hcb52e73_5         313 KB  conda-forge\n",
            "    boost-cpp-1.78.0           |       h6582d0a_3        15.2 MB  conda-forge\n",
            "    brotli-1.1.0               |       hd590300_1          19 KB  conda-forge\n",
            "    brotli-bin-1.1.0           |       hd590300_1          19 KB  conda-forge\n",
            "    ca-certificates-2023.11.17 |       hbcca054_0         151 KB  conda-forge\n",
            "    cairo-1.16.0               |    hbbf8b49_1016         1.1 MB  conda-forge\n",
            "    certifi-2023.11.17         |     pyhd8ed1ab_0         155 KB  conda-forge\n",
            "    chardet-5.2.0              |  py310hff52083_1         241 KB  conda-forge\n",
            "    conda-23.3.1               |  py310hff52083_0         941 KB  conda-forge\n",
            "    contourpy-1.2.0            |  py310hd41b1e2_0         233 KB  conda-forge\n",
            "    cycler-0.12.1              |     pyhd8ed1ab_0          13 KB  conda-forge\n",
            "    expat-2.5.0                |       hcb278e6_1         134 KB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       h77eed37_1         1.5 MB  conda-forge\n",
            "    fontconfig-2.14.2          |       h14ed4e7_0         266 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |                0           4 KB  conda-forge\n",
            "    fonttools-4.46.0           |  py310h2372a71_0         2.2 MB  conda-forge\n",
            "    freetype-2.12.1            |       h267a509_2         620 KB  conda-forge\n",
            "    freetype-py-2.3.0          |     pyhd8ed1ab_0          58 KB  conda-forge\n",
            "    gettext-0.21.1             |       h27087fc_0         4.1 MB  conda-forge\n",
            "    greenlet-3.0.2             |  py310hc6cd4ac_0         201 KB  conda-forge\n",
            "    jsonpatch-1.33             |     pyhd8ed1ab_0          17 KB  conda-forge\n",
            "    jsonpointer-2.4            |  py310hff52083_3          16 KB  conda-forge\n",
            "    kiwisolver-1.4.5           |  py310hd41b1e2_1          71 KB  conda-forge\n",
            "    lcms2-2.15                 |       haa2dc70_1         236 KB  conda-forge\n",
            "    lerc-4.0.0                 |       h27087fc_0         275 KB  conda-forge\n",
            "    libblas-3.9.0              |20_linux64_openblas          14 KB  conda-forge\n",
            "    libbrotlicommon-1.1.0      |       hd590300_1          68 KB  conda-forge\n",
            "    libbrotlidec-1.1.0         |       hd590300_1          32 KB  conda-forge\n",
            "    libbrotlienc-1.1.0         |       hd590300_1         276 KB  conda-forge\n",
            "    libcblas-3.9.0             |20_linux64_openblas          14 KB  conda-forge\n",
            "    libdeflate-1.18            |       h0b41bf4_0          64 KB  conda-forge\n",
            "    libexpat-2.5.0             |       hcb278e6_1          76 KB  conda-forge\n",
            "    libgfortran-ng-13.2.0      |       h69a702a_0          23 KB  conda-forge\n",
            "    libgfortran5-13.2.0        |       ha4646dd_0         1.4 MB  conda-forge\n",
            "    libglib-2.78.3             |       h783c2da_0         2.6 MB  conda-forge\n",
            "    libjpeg-turbo-2.1.5.1      |       hd590300_1         485 KB  conda-forge\n",
            "    liblapack-3.9.0            |20_linux64_openblas          14 KB  conda-forge\n",
            "    libopenblas-0.3.25         |pthreads_h413a1c8_0         5.3 MB  conda-forge\n",
            "    libpng-1.6.39              |       h753d276_0         276 KB  conda-forge\n",
            "    libtiff-4.5.1              |       h8b53f26_1         407 KB  conda-forge\n",
            "    libwebp-base-1.3.2         |       hd590300_0         392 KB  conda-forge\n",
            "    libxcb-1.15                |       h0b41bf4_0         375 KB  conda-forge\n",
            "    matplotlib-base-3.8.0      |  py310h62c0568_1         6.5 MB  conda-forge\n",
            "    munkres-1.1.4              |     pyh9f0ad1d_0          12 KB  conda-forge\n",
            "    numpy-1.26.2               |  py310hb13e2d6_0         6.6 MB  conda-forge\n",
            "    openjpeg-2.5.0             |       hfec8fc6_2         344 KB  conda-forge\n",
            "    openssl-3.2.0              |       hd590300_1         2.7 MB  conda-forge\n",
            "    packaging-23.2             |     pyhd8ed1ab_0          48 KB  conda-forge\n",
            "    pandas-2.1.4               |  py310hcc13569_0        11.8 MB  conda-forge\n",
            "    pcre2-10.42                |       hcad00b1_0         993 KB  conda-forge\n",
            "    pillow-10.0.0              |  py310h582fbeb_0        44.5 MB  conda-forge\n",
            "    pixman-0.42.2              |       h59595ed_0         376 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h36c2ea0_1001           5 KB  conda-forge\n",
            "    pycairo-1.25.0             |  py310hda9f760_1         112 KB  conda-forge\n",
            "    pyparsing-3.1.1            |     pyhd8ed1ab_0          87 KB  conda-forge\n",
            "    python-dateutil-2.8.2      |     pyhd8ed1ab_0         240 KB  conda-forge\n",
            "    python-tzdata-2023.3       |     pyhd8ed1ab_0         140 KB  conda-forge\n",
            "    python_abi-3.10            |          4_cp310           6 KB  conda-forge\n",
            "    pytz-2023.3.post1          |     pyhd8ed1ab_0         183 KB  conda-forge\n",
            "    rdkit-2023.03.2            |  py310h399bcf7_0        34.7 MB  conda-forge\n",
            "    reportlab-4.0.8            |  py310h2372a71_0         2.2 MB  conda-forge\n",
            "    rlpycairo-0.2.0            |     pyhd8ed1ab_0          15 KB  conda-forge\n",
            "    six-1.16.0                 |     pyh6c4a22f_0          14 KB  conda-forge\n",
            "    sqlalchemy-2.0.23          |  py310h2372a71_0         2.7 MB  conda-forge\n",
            "    typing-extensions-4.9.0    |       hd8ed1ab_0          10 KB  conda-forge\n",
            "    typing_extensions-4.9.0    |     pyha770c72_0          35 KB  conda-forge\n",
            "    unicodedata2-15.1.0        |  py310h2372a71_0         365 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h7f98852_1002          27 KB  conda-forge\n",
            "    xorg-libice-1.1.1          |       hd590300_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.4           |       h7391055_0          27 KB  conda-forge\n",
            "    xorg-libx11-1.8.7          |       h8ee46fc_0         809 KB  conda-forge\n",
            "    xorg-libxau-1.0.11         |       hd590300_0          14 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h7f98852_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h0b41bf4_2          49 KB  conda-forge\n",
            "    xorg-libxrender-0.9.11     |       hd590300_0          37 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h7f98852_1002           9 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h0b41bf4_1003          30 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h7f98852_1007          73 KB  conda-forge\n",
            "    zlib-1.2.13                |       h166bdaf_4          92 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       156.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boltons            conda-forge/noarch::boltons-23.0.0-pyhd8ed1ab_0 \n",
            "  boost              conda-forge/linux-64::boost-1.78.0-py310hcb52e73_5 \n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.78.0-h6582d0a_3 \n",
            "  brotli             conda-forge/linux-64::brotli-1.1.0-hd590300_1 \n",
            "  brotli-bin         conda-forge/linux-64::brotli-bin-1.1.0-hd590300_1 \n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hbbf8b49_1016 \n",
            "  chardet            conda-forge/linux-64::chardet-5.2.0-py310hff52083_1 \n",
            "  contourpy          conda-forge/linux-64::contourpy-1.2.0-py310hd41b1e2_0 \n",
            "  cycler             conda-forge/noarch::cycler-0.12.1-pyhd8ed1ab_0 \n",
            "  expat              conda-forge/linux-64::expat-2.5.0-hcb278e6_1 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_1 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.14.2-h14ed4e7_0 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n",
            "  fonttools          conda-forge/linux-64::fonttools-4.46.0-py310h2372a71_0 \n",
            "  freetype           conda-forge/linux-64::freetype-2.12.1-h267a509_2 \n",
            "  freetype-py        conda-forge/noarch::freetype-py-2.3.0-pyhd8ed1ab_0 \n",
            "  gettext            conda-forge/linux-64::gettext-0.21.1-h27087fc_0 \n",
            "  greenlet           conda-forge/linux-64::greenlet-3.0.2-py310hc6cd4ac_0 \n",
            "  jsonpatch          conda-forge/noarch::jsonpatch-1.33-pyhd8ed1ab_0 \n",
            "  jsonpointer        conda-forge/linux-64::jsonpointer-2.4-py310hff52083_3 \n",
            "  kiwisolver         conda-forge/linux-64::kiwisolver-1.4.5-py310hd41b1e2_1 \n",
            "  lcms2              conda-forge/linux-64::lcms2-2.15-haa2dc70_1 \n",
            "  lerc               conda-forge/linux-64::lerc-4.0.0-h27087fc_0 \n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-20_linux64_openblas \n",
            "  libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.1.0-hd590300_1 \n",
            "  libbrotlidec       conda-forge/linux-64::libbrotlidec-1.1.0-hd590300_1 \n",
            "  libbrotlienc       conda-forge/linux-64::libbrotlienc-1.1.0-hd590300_1 \n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-20_linux64_openblas \n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.18-h0b41bf4_0 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.5.0-hcb278e6_1 \n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-13.2.0-h69a702a_0 \n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-13.2.0-ha4646dd_0 \n",
            "  libglib            conda-forge/linux-64::libglib-2.78.3-h783c2da_0 \n",
            "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-2.1.5.1-hd590300_1 \n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-20_linux64_openblas \n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.25-pthreads_h413a1c8_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.39-h753d276_0 \n",
            "  libtiff            conda-forge/linux-64::libtiff-4.5.1-h8b53f26_1 \n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.3.2-hd590300_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.15-h0b41bf4_0 \n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.8.0-py310h62c0568_1 \n",
            "  munkres            conda-forge/noarch::munkres-1.1.4-pyh9f0ad1d_0 \n",
            "  numpy              conda-forge/linux-64::numpy-1.26.2-py310hb13e2d6_0 \n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.5.0-hfec8fc6_2 \n",
            "  packaging          conda-forge/noarch::packaging-23.2-pyhd8ed1ab_0 \n",
            "  pandas             conda-forge/linux-64::pandas-2.1.4-py310hcc13569_0 \n",
            "  pcre2              conda-forge/linux-64::pcre2-10.42-hcad00b1_0 \n",
            "  pillow             conda-forge/linux-64::pillow-10.0.0-py310h582fbeb_0 \n",
            "  pixman             conda-forge/linux-64::pixman-0.42.2-h59595ed_0 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001 \n",
            "  pycairo            conda-forge/linux-64::pycairo-1.25.0-py310hda9f760_1 \n",
            "  pyparsing          conda-forge/noarch::pyparsing-3.1.1-pyhd8ed1ab_0 \n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.2-pyhd8ed1ab_0 \n",
            "  python-tzdata      conda-forge/noarch::python-tzdata-2023.3-pyhd8ed1ab_0 \n",
            "  pytz               conda-forge/noarch::pytz-2023.3.post1-pyhd8ed1ab_0 \n",
            "  rdkit              conda-forge/linux-64::rdkit-2023.03.2-py310h399bcf7_0 \n",
            "  reportlab          conda-forge/linux-64::reportlab-4.0.8-py310h2372a71_0 \n",
            "  rlpycairo          conda-forge/noarch::rlpycairo-0.2.0-pyhd8ed1ab_0 \n",
            "  six                conda-forge/noarch::six-1.16.0-pyh6c4a22f_0 \n",
            "  sqlalchemy         conda-forge/linux-64::sqlalchemy-2.0.23-py310h2372a71_0 \n",
            "  typing-extensions  conda-forge/noarch::typing-extensions-4.9.0-hd8ed1ab_0 \n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.9.0-pyha770c72_0 \n",
            "  unicodedata2       conda-forge/linux-64::unicodedata2-15.1.0-py310h2372a71_0 \n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h7f98852_1002 \n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.1-hd590300_0 \n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.4-h7391055_0 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.7-h8ee46fc_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.11-hd590300_0 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h7f98852_0 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h0b41bf4_2 \n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.11-hd590300_0 \n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h7f98852_1002 \n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h0b41bf4_1003 \n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h7f98852_1007 \n",
            "  zlib               conda-forge/linux-64::zlib-1.2.13-h166bdaf_4 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2022.12.7-ha878542_0 --> 2023.11.17-hbcca054_0 \n",
            "  certifi                            2022.12.7-pyhd8ed1ab_0 --> 2023.11.17-pyhd8ed1ab_0 \n",
            "  conda                              23.1.0-py310hff52083_0 --> 23.3.1-py310hff52083_0 \n",
            "  openssl                                  3.1.0-h0b41bf4_0 --> 3.2.0-hd590300_1 \n",
            "  python_abi                                   3.10-3_cp310 --> 3.10-4_cp310 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "pixman-0.42.2        | 376 KB    | :   0% 0/1 [00:00<?, ?it/s]\n",
            "pthread-stubs-0.4    | 5 KB      | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "typing_extensions-4. | 35 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cycler-0.12.1        | 13 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "lerc-4.0.0           | 275 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libpng-1.6.39        | 276 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-bin-1.1.0     | 19 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fonts-conda-ecosyste | 4 KB      | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.25   | 5.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.78.3       | 2.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zlib-1.2.13          | 92 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-dateutil-2.8. | 240 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fontconfig-2.14.2    | 266 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "greenlet-3.0.2       | 201 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcblas-3.9.0       | 14 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-xextproto-7.3.0 | 30 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-renderproto-0.1 | 9 KB      | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-13.2.0  | 1.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.3.2   | 392 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.42.2        | 376 KB    | :   4% 0.04252171633675829/1 [00:00<00:04,  4.94s/it]\n",
            "\n",
            "\n",
            "cycler-0.12.1        | 13 KB     | : 100% 1.0/1 [00:00<00:00,  4.76it/s]\u001b[A\u001b[A\u001b[A\n",
            "pthread-stubs-0.4    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  4.30it/s]\u001b[A\n",
            "pthread-stubs-0.4    | 5 KB      | : 100% 1.0/1 [00:00<00:00,  4.30it/s]\u001b[A\n",
            "\n",
            "typing_extensions-4. | 35 KB     | :  45% 0.4543790559653891/1 [00:00<00:00,  1.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libpng-1.6.39        | 276 KB    | :   6% 0.05797614287382475/1 [00:00<00:04,  4.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-bin-1.1.0     | 19 KB     | :  86% 0.8632244467860907/1 [00:00<00:00,  3.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fonts-conda-ecosyste | 4 KB      | : 100% 1.0/1 [00:00<00:00,  3.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cycler-0.12.1        | 13 KB     | : 100% 1.0/1 [00:00<00:00,  4.76it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "lerc-4.0.0           | 275 KB    | :   6% 0.05814093783490302/1 [00:00<00:04,  4.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.25   | 5.3 MB    | :   0% 0.0029546439432233717/1 [00:00<01:46, 106.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zlib-1.2.13          | 92 KB     | :  17% 0.1741144964346061/1 [00:00<00:01,  1.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.78.3       | 2.6 MB    | :   1% 0.006076360236482565/1 [00:00<00:54, 54.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fontconfig-2.14.2    | 266 KB    | :   6% 0.060233079666188745/1 [00:00<00:05,  5.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-dateutil-2.8. | 240 KB    | :   7% 0.06660514580038783/1 [00:00<00:05,  5.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "greenlet-3.0.2       | 201 KB    | :   8% 0.07944759096904337/1 [00:00<00:04,  4.81s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "typing_extensions-4. | 35 KB     | : 100% 1.0/1 [00:00<00:00,  2.66it/s]               \u001b[A\u001b[A\n",
            "\n",
            "typing_extensions-4. | 35 KB     | : 100% 1.0/1 [00:00<00:00,  2.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcblas-3.9.0       | 14 KB     | : 100% 1.0/1 [00:00<00:00,  2.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.42.2        | 376 KB    | : 100% 1.0/1 [00:00<00:00,  2.52it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.78.3       | 2.6 MB    | :  60% 0.5954833031752913/1 [00:00<00:00,  1.73it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-xextproto-7.3.0 | 30 KB     | :  54% 0.5412619755533532/1 [00:00<00:00,  1.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-renderproto-0.1 | 9 KB      | : 100% 1.0/1 [00:00<00:00,  2.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-13.2.0  | 1.4 MB    | :   1% 0.011365157717229271/1 [00:00<00:40, 41.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-bin-1.1.0     | 19 KB     | : 100% 1.0/1 [00:00<00:00,  3.20it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.3.2   | 392 KB    | :   4% 0.04077346141403081/1 [00:00<00:11, 12.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fonts-conda-ecosyste | 4 KB      | : 100% 1.0/1 [00:00<00:00,  3.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.25   | 5.3 MB    | :  59% 0.5879741447014509/1 [00:00<00:00,  1.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libpng-1.6.39        | 276 KB    | : 100% 1.0/1 [00:00<00:00,  1.89it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libpng-1.6.39        | 276 KB    | : 100% 1.0/1 [00:00<00:00,  1.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zlib-1.2.13          | 92 KB     | : 100% 1.0/1 [00:00<00:00,  1.63it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zlib-1.2.13          | 92 KB     | : 100% 1.0/1 [00:00<00:00,  1.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "lerc-4.0.0           | 275 KB    | : 100% 1.0/1 [00:00<00:00,  1.45it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "lerc-4.0.0           | 275 KB    | : 100% 1.0/1 [00:00<00:00,  1.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fontconfig-2.14.2    | 266 KB    | : 100% 1.0/1 [00:01<00:00,  1.05it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "fontconfig-2.14.2    | 266 KB    | : 100% 1.0/1 [00:01<00:00,  1.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-dateutil-2.8. | 240 KB    | : 100% 1.0/1 [00:01<00:00,  1.01it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-dateutil-2.8. | 240 KB    | : 100% 1.0/1 [00:01<00:00,  1.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcblas-3.9.0       | 14 KB     | : 100% 1.0/1 [00:01<00:00,  2.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-renderproto-0.1 | 9 KB      | : 100% 1.0/1 [00:01<00:00,  2.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-xextproto-7.3.0 | 30 KB     | : 100% 1.0/1 [00:01<00:00,  1.54s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-xextproto-7.3.0 | 30 KB     | : 100% 1.0/1 [00:01<00:00,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "greenlet-3.0.2       | 201 KB    | : 100% 1.0/1 [00:01<00:00,  1.39s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "greenlet-3.0.2       | 201 KB    | : 100% 1.0/1 [00:01<00:00,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.3.2   | 392 KB    | : 100% 1.0/1 [00:01<00:00,  1.67s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.3.2   | 392 KB    | : 100% 1.0/1 [00:01<00:00,  1.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-13.2.0  | 1.4 MB    | : 100% 1.0/1 [00:02<00:00,  2.21s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgfortran5-13.2.0  | 1.4 MB    | : 100% 1.0/1 [00:02<00:00,  2.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.78.3       | 2.6 MB    | : 100% 1.0/1 [00:02<00:00,  3.19s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libglib-2.78.3       | 2.6 MB    | : 100% 1.0/1 [00:02<00:00,  3.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.25   | 5.3 MB    | : 100% 1.0/1 [00:03<00:00,  3.98s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.25   | 5.3 MB    | : 100% 1.0/1 [00:03<00:00,  3.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 23.3.1\n",
            "  latest version: 23.11.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "Or to minimize the number of packages updated during conda update use\n",
            "\n",
            "     conda install conda=23.11.0\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - deepsmiles\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    deepsmiles-1.0.1           |             py_0          11 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:          11 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  deepsmiles         conda-forge/noarch::deepsmiles-1.0.1-py_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "                                                                        \n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Collecting transformers==4.31.0\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting SmilesPE==0.0.3\n",
            "  Downloading SmilesPE-0.0.3-py3-none-any.whl (15 kB)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m773.9/773.9 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (2.28.2)\n",
            "Collecting safetensors>=0.3.1\n",
            "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (23.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers==4.31.0) (1.26.2)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gensim\n",
            "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastprogress\n",
            "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
            "Collecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.9.0)\n",
            "Collecting smart-open>=1.8.1\n",
            "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.7.0\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (2023.11.17)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers==4.31.0) (3.1.0)\n",
            "Installing collected packages: tokenizers, smart-open, scipy, safetensors, regex, pyyaml, fsspec, filelock, fastprogress, huggingface-hub, gensim, transformers, SmilesPE\n",
            "Successfully installed SmilesPE-0.0.3 fastprogress-1.0.3 filelock-3.13.1 fsspec-2023.12.2 gensim-4.3.2 huggingface-hub-0.19.4 pyyaml-6.0.1 regex-2023.10.3 safetensors-0.4.1 scipy-1.11.4 smart-open-6.4.0 tokenizers-0.13.3 transformers-4.31.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Git Repository"
      ],
      "metadata": {
        "id": "3IdFCwajG1dT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the repository from Github"
      ],
      "metadata": {
        "id": "TdYlBa_kHEP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MD7NeA_4_wv",
        "outputId": "b49b0a79-6895-4fea-f09d-7a543a934601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'HBCVTr'...\n",
            "remote: Enumerating objects: 170, done.\u001b[K\n",
            "remote: Counting objects: 100% (100/100), done.\u001b[K\n",
            "remote: Compressing objects: 100% (94/94), done.\u001b[K\n",
            "remote: Total 170 (delta 58), reused 12 (delta 4), pack-reused 70\u001b[K\n",
            "Receiving objects: 100% (170/170), 182.41 KiB | 4.68 MiB/s, done.\n",
            "Resolving deltas: 100% (92/92), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/imeewan/HBCVTr"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change directory to the cloned repository."
      ],
      "metadata": {
        "id": "7lVLobK2HGcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd HBCVTr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztuFTNXT9vkG",
        "outputId": "96b849fc-84f5-4881-80fc-f19f2c6cd79b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/HBCVTr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Models"
      ],
      "metadata": {
        "id": "nxoIHlDCJ-xq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we download the trained models from Google Drive."
      ],
      "metadata": {
        "id": "cxp4Ay94KASG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1hDDNY9kE3Y-IFJEeILDxwG5NbRWMCWA8\n",
        "!gdown --id 1vAkxP3y-FD5N5BpbfXIzTn5-nORlnv4T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsoUJ9OlIZL2",
        "outputId": "98f690d6-dc04-4d32-ba8f-50ab9e5c32e2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hDDNY9kE3Y-IFJEeILDxwG5NbRWMCWA8\n",
            "To: /content/HBCVTr/hbv_model.pt\n",
            "100% 1.12G/1.12G [00:18<00:00, 59.0MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vAkxP3y-FD5N5BpbfXIzTn5-nORlnv4T\n",
            "To: /content/HBCVTr/hcv_model.pt\n",
            "100% 1.12G/1.12G [00:15<00:00, 72.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv hbv_model.pt model/\n",
        "!mv hcv_model.pt model/"
      ],
      "metadata": {
        "id": "lix2ntzMTs98"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Demo"
      ],
      "metadata": {
        "id": "6AOCzenpHK6g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this demo, we will run a prediction using our HBCVTr model."
      ],
      "metadata": {
        "id": "il3nDeMCHOT-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's import all necessary packages."
      ],
      "metadata": {
        "id": "TqBbehy4HYj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from BartDataset import BartDataset\n",
        "from CustomBart_Atomic_Tokenizer import CustomBart_Atomic_Tokenizer\n",
        "from CustomBart_FG_Tokenizer import CustomBart_FG_Tokenizer\n",
        "from TqdmWrap import TqdmWrap\n",
        "from DualInputDataset import DualInputDataset\n",
        "from DualBartModel import DualBartModel, CustomBartModel\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, RandomSampler, Dataset\n",
        "from torch.optim import AdamW\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import deepsmiles\n",
        "from SmilesPE.tokenizer import *\n",
        "from SmilesPE.pretokenizer import atomwise_tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from rdkit import Chem\n",
        "import codecs\n",
        "from transformers import AdamW, BartTokenizer, BartForConditionalGeneration, BartConfig, get_linear_schedule_with_warmup, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, PreTrainedTokenizer\n",
        "import re\n",
        "from tqdm.auto import tqdm\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "import json\n",
        "import os\n",
        "from utils import *\n",
        "from pretrained_utils import *\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import SaltRemover"
      ],
      "metadata": {
        "id": "gsmwv3zo5XMk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input the smiles and virus choice to predict here."
      ],
      "metadata": {
        "id": "g9-Vktljmacj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# smiles = input(\"Enter the SMILES of the compound: \")\n",
        "smiles = 'C[C@H](Cn1cnc2c(N)ncnc21)OCP(=O)(O)OP(=O)(O)CO[C@H](C)Cn1cnc2c(N)ncnc21'\n",
        "# virus_choice = input(\"Do you want to predict the compound's activity against HBV or HCV? (Enter HBV or HCV): \").lower()\n",
        "virus_choice = 'hbv'"
      ],
      "metadata": {
        "id": "qHH4gjRHmYmc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we run the prediction."
      ],
      "metadata": {
        "id": "w-FO2giEmeQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Analysis in progress ...\")\n",
        "\n",
        "if virus_choice == 'hbv':\n",
        "  model_path = \"model/hbv_model.pt\"\n",
        "  max_pact = max_pact_hbv\n",
        "  min_pact = min_pact_hbv\n",
        "elif virus_choice == 'hcv':\n",
        "  model_path = \"model/hcv_model.pt\"\n",
        "  max_pact = max_pact_hcv\n",
        "  min_pact = min_pact_hcv\n",
        "else:\n",
        "  raise ValueError(\"Invalid input. Please enter either 'HBV' or 'HCV'.\")\n",
        "\n",
        "max_length = 250\n",
        "\n",
        "model = DualBartModel(config1, config2, reg_mod)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.to(device)\n",
        "\n",
        "smiles_data_no_salt = remove_salt(smiles)\n",
        "smiles = smiles_data_no_salt\n",
        "\n",
        "input_encoding1 = tokenizer1.encode_plus(smiles, truncation=True, max_length=max_length, padding='max_length', return_tensors=\"pt\")\n",
        "input_encoding2 = tokenizer2.encode_plus(smiles, truncation=True, max_length=max_length, padding='max_length', return_tensors=\"pt\")\n",
        "\n",
        "input_ids1 = input_encoding1['input_ids'].to(device)\n",
        "attention_mask1 = input_encoding1['attention_mask'].to(device)\n",
        "input_ids2 = input_encoding2['input_ids'].to(device)\n",
        "attention_mask2 = input_encoding2['attention_mask'].to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  output = model(input_ids1=input_ids1, attention_mask1=attention_mask1,\n",
        "                  input_ids2=input_ids2, attention_mask2=attention_mask2)\n",
        "\n",
        "prediction = output\n",
        "prediction_value = prediction.cpu().numpy()[0]\n",
        "print('SMILES: ', smiles)\n",
        "print('Predicted pACT: ', prediction_value * (max_pact - min_pact) + min_pact)\n",
        "predicted_EC50 = 10**-(prediction_value * (max_pact - min_pact) + min_pact) * 10**9\n",
        "print('Predicted EC50 :', predicted_EC50, 'nM')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POoCv3Fz5j5a",
        "outputId": "35fdfc62-493c-4252-d049-cf42991ce8fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis in progress ...\n",
            "SMILES:  C[C@H](Cn1cnc2c(N)ncnc21)OCP(=O)(O)OP(=O)(O)CO[C@H](C)Cn1cnc2c(N)ncnc21\n",
            "Predicted pACT:  8.122957168817521\n",
            "Predicted EC50 : 7.534298651631602 nM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Demo"
      ],
      "metadata": {
        "id": "wKclaEiVrGTu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Parameters"
      ],
      "metadata": {
        "id": "sGTXbsuIrQyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Pytorch device."
      ],
      "metadata": {
        "id": "_uShX1W4LTtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "I2uzGJ0nLWM1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for training a model."
      ],
      "metadata": {
        "id": "qtYOK0omK4sw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def training_model(combinations):\n",
        "    for idx, (d_model1, encoder_ffn_dim1, num_attention_heads1, num_hidden_layers1, dropout1, lr1) in enumerate(combinations):\n",
        "\n",
        "        (d_model2, encoder_ffn_dim2, num_attention_heads2, num_hidden_layers2, dropout2, lr2) = (d_model1, encoder_ffn_dim1, num_attention_heads1, num_hidden_layers1, dropout1, lr1)\n",
        "\n",
        "        max_r2 = -100\n",
        "\n",
        "        config1 = BartConfig(\n",
        "            vocab_size=len(atomic_vocab),\n",
        "            d_model=d_model1,\n",
        "            encoder_ffn_dim=encoder_ffn_dim1,\n",
        "            num_attention_heads=num_attention_heads1,\n",
        "            num_hidden_layers=num_hidden_layers1,\n",
        "            pad_token_id=tokenizer1.pad_token_id,\n",
        "            max_position_embeddings=max_length,\n",
        "            dropout=dropout1,\n",
        "        )\n",
        "\n",
        "        config2 = BartConfig(\n",
        "            vocab_size=len(fg_vocab),\n",
        "            d_model=d_model2,\n",
        "            encoder_ffn_dim=encoder_ffn_dim2,\n",
        "            num_attention_heads=num_attention_heads2,\n",
        "            num_hidden_layers=num_hidden_layers2,\n",
        "            pad_token_id=tokenizer2.pad_token_id,\n",
        "            max_position_embeddings=max_length,\n",
        "            dropout=dropout2,\n",
        "        )\n",
        "\n",
        "\n",
        "        model = DualBartModel(config1, config2, reg_mod)\n",
        "        model.to(device)\n",
        "        model.apply(weights_init)\n",
        "        optimizer = AdamW(model.parameters(), lr=lr1, weight_decay=weight_decay)\n",
        "\n",
        "        print(f\"Model {idx+1} configurations: \")\n",
        "        print(f\"d_model1: {d_model1}, encoder_ffn_dim1: {encoder_ffn_dim1}, num_attention_heads1: {num_attention_heads1}, num_hidden_layers1: {num_hidden_layers1}\")\n",
        "        print(f\"d_model2: {d_model2}, encoder_ffn_dim2: {encoder_ffn_dim2}, num_attention_heads2: {num_attention_heads2}, num_hidden_layers2: {num_hidden_layers2}\")\n",
        "\n",
        "        log_file_path = f\"model/new_model2.log\"\n",
        "\n",
        "        os.makedirs(os.path.dirname(log_file_path), exist_ok=True)\n",
        "\n",
        "        config_dict = {\n",
        "            'd_model1': d_model1,\n",
        "            'encoder_ffn_dim1': encoder_ffn_dim1,\n",
        "            'num_attention_heads1': num_attention_heads1,\n",
        "            'num_hidden_layers1': num_hidden_layers1,\n",
        "            'd_model2': d_model2,\n",
        "            'encoder_ffn_dim2': encoder_ffn_dim2,\n",
        "            'num_attention_heads2': num_attention_heads2,\n",
        "            'num_hidden_layers2': num_hidden_layers2,\n",
        "            'dropout1': dropout1,\n",
        "            'dropout2': dropout2,\n",
        "            'lr': lr1,\n",
        "            'regression_dim': reg_mod,\n",
        "            'weight_decay': weight_decay,\n",
        "        }\n",
        "\n",
        "        with open(log_file_path, 'w') as outfile:\n",
        "            outfile.write(json.dumps(config_dict) + '\\n')\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            total_train_loss = 0\n",
        "\n",
        "            for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\", dynamic_ncols=True)):\n",
        "                inputs1, inputs2 = batch['input_ids1'].to(device).long(), batch['input_ids2'].to(device).long()\n",
        "                attention_mask1, attention_mask2 = batch['attention_mask1'].to(device).long(), batch['attention_mask2'].to(device).long()\n",
        "\n",
        "                labels = batch['labels'].to(device).float()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(input_ids1=inputs1, attention_mask1=attention_mask1,\n",
        "                                input_ids2=inputs2, attention_mask2=attention_mask2)\n",
        "                pred = outputs\n",
        "                loss = torch.nn.MSELoss()(pred, labels)\n",
        "\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "            model.eval()\n",
        "            total_eval_loss = 0\n",
        "            total_eval_r2 = 0\n",
        "\n",
        "            for batch in val_dataloader:\n",
        "                with torch.no_grad():\n",
        "                    inputs1, inputs2 = batch['input_ids1'].to(device).long(), batch['input_ids2'].to(device).long()\n",
        "                    attention_mask1, attention_mask2 = batch['attention_mask1'].to(device).long(), batch['attention_mask2'].to(device).long()\n",
        "\n",
        "                    labels = batch['labels'].to(device).float()\n",
        "\n",
        "                    outputs = model(input_ids1=inputs1, attention_mask1=attention_mask1,\n",
        "                                    input_ids2=inputs2, attention_mask2=attention_mask2)\n",
        "                    pred = outputs\n",
        "                    loss = torch.nn.MSELoss()(pred, labels)\n",
        "                    total_eval_loss += loss.item()\n",
        "                    total_eval_r2 += r2_score(labels.cpu().numpy(), pred.cpu().detach().numpy())\n",
        "\n",
        "            avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "            avg_val_r2 = total_eval_r2 / len(val_dataloader)\n",
        "\n",
        "            log_dict = {\n",
        "                'epoch': epoch+1,\n",
        "                'avg_train_loss': avg_train_loss,\n",
        "                'avg_val_loss': avg_val_loss,\n",
        "                'avg_val_r2': avg_val_r2,\n",
        "\n",
        "            }\n",
        "\n",
        "            with open(log_file_path, 'a') as outfile:\n",
        "                outfile.write(json.dumps(log_dict) + '\\n')\n",
        "\n",
        "            if avg_val_r2 > max_r2:\n",
        "                torch.save(model.state_dict(), f\"model/new_model2.pt\")\n",
        "                max_r2 = avg_val_r2"
      ],
      "metadata": {
        "id": "IIzAhPBZK8qE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set training parameters and perform tokenization."
      ],
      "metadata": {
        "id": "QbD4AgzzLE-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 250\n",
        "batch_size = 8\n",
        "\n",
        "data_path = \"data/hbv_dataset.csv\"\n",
        "train_dataloader, val_dataloader = train_val_proc(data_path)\n",
        "\n",
        "d_models = [16]\n",
        "encoder_ffn_dims = [16]\n",
        "num_attention_heads = [2]\n",
        "num_hidden_layers = [1]\n",
        "dropouts = [0.15]\n",
        "learning_rates = [1e-6]\n",
        "reg_mod = [32, 32]\n",
        "weight_decay = 0.001\n",
        "num_epochs = 50\n",
        "\n",
        "param_combinations = list(itertools.product(d_models, encoder_ffn_dims, num_attention_heads, num_hidden_layers, dropouts, learning_rates))\n",
        "combinations = param_combinations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkC4QXsEK-i4",
        "outputId": "ca21e27b-de10-41c1-a356-f7f261ebe445"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1552/1552 [00:00<00:00, 6296.72it/s]\n",
            "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 389/389 [00:00<00:00, 9434.39it/s]\n",
            "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1552/1552 [00:10<00:00, 147.10it/s]\n",
            "Tokenizing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 389/389 [00:02<00:00, 172.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, train the model."
      ],
      "metadata": {
        "id": "-0ctfzNNLqOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_model(combinations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SemAHT_LLNlt",
        "outputId": "e4230927-a822-465d-af14-e930baf919a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 configurations: \n",
            "d_model1: 16, encoder_ffn_dim1: 16, num_attention_heads1: 2, num_hidden_layers1: 1\n",
            "d_model2: 16, encoder_ffn_dim2: 16, num_attention_heads2: 2, num_hidden_layers2: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rIteration:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f3Auv3ptryw5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}